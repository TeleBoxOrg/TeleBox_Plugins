import { Plugin } from "@utils/pluginBase";
import { Api } from "telegram";
import axios from "axios";
import * as fs from "fs";
import * as path from "path";
import * as os from "os";

// é…ç½®å­˜å‚¨é”®å
const CONFIG_KEYS = {
  GPT_KEY: "gpt_key",
  GPT_API: "gpt_api",
  GPT_MODEL: "gpt_model",
  GPT_VISION_MODEL: "gpt_vision_model",
  GPT_IMAGE_UPLOAD: "gpt_image_upload",
  GPT_WEB_SEARCH: "gpt_web_search",
  GPT_AUTO_REMOVE: "gpt_auto_remove",
  GPT_MAX_TOKENS: "gpt_max_tokens",
  GPT_COLLAPSE: "gpt_collapse",
};

// é»˜è®¤é…ç½®
const DEFAULT_CONFIG = {
  [CONFIG_KEYS.GPT_API]: "https://api.openai.com",
  [CONFIG_KEYS.GPT_MODEL]: "gpt-4o",
  [CONFIG_KEYS.GPT_VISION_MODEL]: "gpt-4o",
  [CONFIG_KEYS.GPT_IMAGE_UPLOAD]: "false",
  [CONFIG_KEYS.GPT_WEB_SEARCH]: "false",
  [CONFIG_KEYS.GPT_AUTO_REMOVE]: "false",
  [CONFIG_KEYS.GPT_MAX_TOKENS]: "888",
  [CONFIG_KEYS.GPT_COLLAPSE]: "false",
};

// é…ç½®ç®¡ç†å™¨
class ConfigManager {
  private static storage: { [key: string]: string } = {};

  static get(key: string, defaultValue?: string): string {
    return this.storage[key] || defaultValue || DEFAULT_CONFIG[key] || "";
  }

  static set(key: string, value: string): void {
    this.storage[key] = value;
  }
}

// HTMLè½¬ä¹‰å‡½æ•°
function htmlEscape(text: string): string {
  return text
    .replace(/&/g, "&amp;")
    .replace(/</g, "&lt;")
    .replace(/>/g, "&gt;")
    .replace(/"/g, "&quot;")
    .replace(/'/g, "&#x27;");
}

// ç¡çœ å‡½æ•°
function sleep(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}

// å›¾ç‰‡ä¸Šä¼ åˆ° fars.ee
async function uploadImage(imagePath: string): Promise<string> {
  const basename = path.basename(imagePath);
  const url = `https://fars.ee/~${basename}`;

  const formData = new FormData();
  const imageBuffer = await fs.promises.readFile(imagePath);
  const imageBlob = new Blob([imageBuffer]);
  
  formData.append('c', imageBlob, basename);
  formData.append('sunset', '120');
  formData.append('private', '1');

  const headers = {
    'Accept': 'application/json'
  };

  try {
    const response = await axios.post(url, formData, {
      headers,
      timeout: 30000
    });

    if (response.status !== 200) {
      const location = response.headers.location;
      if (location) {
        return location;
      }
      throw new Error(`å“åº”å¼‚å¸¸: HTTP ${response.status}`);
    }

    const data = response.data;
    let retUrl = data.url;
    
    if (!retUrl) {
      retUrl = response.headers.location;
    }
    
    if (!retUrl) {
      throw new Error("æœ‰å“åº”ä½†æ— æ³•è·å–å›¾ç‰‡ URL");
    }
    
    return retUrl;
  } catch (error: any) {
    throw new Error(`ä¸Šä¼ å›¾ç‰‡å¤±è´¥: ${error.message}`);
  }
}

// ä¸‹è½½å¹¶å¤„ç†å›¾ç‰‡
async function downloadAndProcessImage(
  client: Api.TelegramClient,
  message: Api.Message,
  infoMessage: Api.Message
): Promise<{ imagePath: string; imageSource: string }> {
  const tempDir = os.tmpdir();
  const imageName = `gpt_tmp_${Math.random().toString(36).substring(7)}_${Date.now()}.png`;
  const imagePath = path.join(tempDir, imageName);

  try {
    // ä¸‹è½½å›¾ç‰‡
    await infoMessage.edit({ text: "ä¸‹è½½å›¾ç‰‡..." });
    
    let mediaMsg = message;
    const replyMsg = await message.getReplyMessage();
    if (!message.media && replyMsg?.media) {
      mediaMsg = replyMsg;
    }

    if (!mediaMsg.media) {
      throw new Error("æœªæ‰¾åˆ°å›¾ç‰‡");
    }

    // å°è¯•ä¸‹è½½å›¾ç‰‡
    const buffer = await client.downloadMedia(mediaMsg.media, { 
      workers: 1,
      progressCallback: (received: number, total: number) => {
        const percent = (received * 100 / total);
        infoMessage.edit({
          text: `ä¸‹è½½å›¾ç‰‡ ${percent.toFixed(1)}%`
        }).catch(() => {});
      }
    });

    if (!buffer) {
      throw new Error("å›¾ç‰‡ä¸‹è½½å¤±è´¥");
    }

    // ä¿å­˜å›¾ç‰‡
    await fs.promises.writeFile(imagePath, buffer as any);
    await infoMessage.edit({ text: "ä¸‹è½½å›¾ç‰‡ 100%" });

    // æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸Šä¼ å›¾ç‰‡
    const imageUploadEnabled = ConfigManager.get(CONFIG_KEYS.GPT_IMAGE_UPLOAD).toLowerCase() === 'true';
    
    let imageSource: string;
    if (imageUploadEnabled) {
      const imageUrl = await uploadImage(imagePath);
      imageSource = imageUrl;
    } else {
      const imageBuffer = await fs.promises.readFile(imagePath);
      const base64 = imageBuffer.toString('base64');
      imageSource = `data:image/png;base64,${base64}`;
    }

    return { imagePath, imageSource };
  } catch (error) {
    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    try {
      await fs.promises.unlink(imagePath);
    } catch {}
    throw error;
  }
}

// è®¾ç½®max_tokenså‚æ•°ï¼ˆå…¼å®¹ä¸åŒæ¨¡å‹ï¼‰
function setMaxTokensParam(payload: any, modelName: string, maxTokens: number | null): void {
  if (maxTokens === null) return;
  
  const modelLower = modelName.toLowerCase();
  if (modelLower.startsWith("gpt-5") || modelLower.startsWith("o1-")) {
    payload.max_completion_tokens = maxTokens;
  } else {
    payload.max_tokens = maxTokens;
  }
}

// è°ƒç”¨GPT API
async function callGptApi(
  question: string,
  imageSource?: string,
  useVision = false
): Promise<string> {
  const apiKey = ConfigManager.get(CONFIG_KEYS.GPT_KEY);
  const apiUrl = ConfigManager.get(CONFIG_KEYS.GPT_API);
  const model = useVision 
    ? ConfigManager.get(CONFIG_KEYS.GPT_VISION_MODEL)
    : ConfigManager.get(CONFIG_KEYS.GPT_MODEL);
  const webSearch = ConfigManager.get(CONFIG_KEYS.GPT_WEB_SEARCH).toLowerCase() === 'true';
  const maxTokensStr = ConfigManager.get(CONFIG_KEYS.GPT_MAX_TOKENS);

  if (!apiKey) {
    throw new Error("æœªè®¾ç½® API Key");
  }
  if (!apiUrl) {
    throw new Error("æœªè®¾ç½® API URL");
  }
  if (!model) {
    throw new Error("æœªè®¾ç½®æ¨¡å‹");
  }

  let maxTokens: number | null = null;
  try {
    const parsed = parseInt(maxTokensStr);
    if (parsed === -1) {
      maxTokens = null;
    } else {
      maxTokens = parsed;
    }
  } catch {
    maxTokens = 888;
  }

  const useResponsesApi = webSearch;
  const url = useResponsesApi 
    ? `${apiUrl}/v1/responses`
    : `${apiUrl}/v1/chat/completions`;

  let payload: any;

  if (useVision && imageSource) {
    if (useResponsesApi) {
      // Responses API with vision
      payload = {
        model,
        input: [
          {
            role: "user",
            content: [
              { type: "input_text", text: question },
              { type: "input_image", image_url: imageSource }
            ]
          }
        ],
        tools: [{ type: "web_search" }],
        tool_choice: "auto",
        temperature: model.startsWith('o1-') || model.startsWith('gpt-5') ? 1 : 0.5
      };
      if (maxTokens !== null) {
        payload.max_output_tokens = maxTokens;
      }
    } else {
      // Chat Completions with vision
      payload = {
        stream: false,
        model,
        messages: [
          {
            role: "user",
            content: [
              { type: "text", text: question },
              { type: "image_url", image_url: { url: imageSource } }
            ]
          }
        ],
        temperature: model.startsWith('o1-') || model.startsWith('gpt-5') ? 1 : 0.5,
        presence_penalty: 0
      };
      setMaxTokensParam(payload, model, maxTokens);
    }
  } else {
    if (useResponsesApi) {
      // Responses API
      payload = {
        model,
        input: question,
        tools: [{ type: "web_search" }],
        tool_choice: "auto",
        temperature: model.startsWith('o1-') || model.startsWith('gpt-5') ? 1 : 0.5
      };
      if (maxTokens !== null) {
        payload.max_output_tokens = maxTokens;
      }
    } else {
      // Chat Completions
      payload = {
        stream: false,
        model,
        messages: [
          { role: "user", content: question }
        ],
        temperature: model.startsWith('o1-') || model.startsWith('gpt-5') ? 1 : 0.5,
        presence_penalty: 0
      };
      setMaxTokensParam(payload, model, maxTokens);
    }
  }

  const headers = {
    'Authorization': `Bearer ${apiKey}`,
    'Content-Type': 'application/json'
  };

  const timeout = useResponsesApi ? 120000 : 30000;
  
  try {
    const response = await axios.post(url, payload, {
      headers,
      timeout
    });

    if (response.status !== 200) {
      throw new Error(`API è¯·æ±‚å¤±è´¥: HTTP ${response.status}`);
    }

    const data = response.data;
    let answer: string | null = null;

    if (useResponsesApi) {
      // Handle Responses API response
      let responseData = data;
      const startTime = Date.now();
      
      // Poll if response is still processing
      while (
        responseData.status === "in_progress" || 
        responseData.status === "queued"
      ) {
        if (Date.now() - startTime > timeout - 5000) {
          break;
        }
        
        await sleep(1000);
        const pollResponse = await axios.get(
          `${apiUrl}/v1/responses/${responseData.id}`,
          { headers, timeout: 20000 }
        );
        responseData = pollResponse.data;
      }

      // Extract answer from Responses API
      answer = responseData.output_text;
      if (!answer && responseData.output) {
        const parts: string[] = [];
        for (const item of responseData.output) {
          if (item.content && Array.isArray(item.content)) {
            for (const c of item.content) {
              const text = c.text || c.content || c.value;
              if (typeof text === 'string') {
                parts.push(text);
              }
            }
          }
        }
        answer = parts.join('').trim() || null;
      }
    } else {
      // Handle Chat Completions response
      answer = data.choices?.[0]?.message?.content;
    }

    if (!answer) {
      throw new Error("API è¿”å›äº†ç©ºçš„å›ç­”");
    }

    return answer;
  } catch (error: any) {
    if (error.response?.data?.error?.message) {
      throw new Error(error.response.data.error.message);
    }
    throw new Error(`API è°ƒç”¨å¤±è´¥: ${error.message}`);
  }
}

// æ ¼å¼åŒ–å›ç­”æ¶ˆæ¯
function formatResponse(question: string, answer: string): string {
  let finalText = "";

  if (question.trim()) {
    // æ·»åŠ é—®é¢˜éƒ¨åˆ†
    finalText += "<b>Q:</b>\n";
    finalText += `<blockquote>${htmlEscape(question)}</blockquote>\n\n`;
  }

  // æ·»åŠ å›ç­”éƒ¨åˆ†
  finalText += "<b>A:</b>\n";
  finalText += `<blockquote>${htmlEscape(answer)}</blockquote>`;

  return finalText;
}

// æ¸…ç†ä¸´æ—¶æ–‡ä»¶
async function cleanupTempFile(filePath?: string): Promise<void> {
  if (filePath) {
    try {
      await fs.promises.unlink(filePath);
    } catch {
      // å¿½ç•¥æ¸…ç†é”™è¯¯
    }
  }
}

// ä¸»å¤„ç†å‡½æ•°
async function handleGptRequest(msg: Api.Message): Promise<void> {
  const [, ...args] = msg.message.slice(1).split(" ");
  let tempImagePath: string | undefined;

  try {
    // æ£€æŸ¥æ˜¯å¦æ˜¯é…ç½®å‘½ä»¤
    if (args.length === 2 && args[0].startsWith("_set_")) {
      const configKey = args[0];
      const configValue = args[1].trim();
      
      let actualKey: string;
      let displayName: string;
      
      switch (configKey) {
        case "_set_key":
          actualKey = CONFIG_KEYS.GPT_KEY;
          displayName = "API Key";
          break;
        case "_set_api":
          actualKey = CONFIG_KEYS.GPT_API;
          displayName = "API URL";
          break;
        case "_set_model":
          actualKey = CONFIG_KEYS.GPT_MODEL;
          displayName = "æ¨¡å‹";
          break;
        case "_set_vision_model":
          actualKey = CONFIG_KEYS.GPT_VISION_MODEL;
          displayName = "å›¾åƒè¯†åˆ«æ¨¡å‹";
          break;
        case "_set_image_upload":
          actualKey = CONFIG_KEYS.GPT_IMAGE_UPLOAD;
          displayName = "å›¾ç‰‡ä¸Šä¼ ";
          break;
        case "_set_web_search":
          actualKey = CONFIG_KEYS.GPT_WEB_SEARCH;
          displayName = "Webæœç´¢";
          break;
        case "_set_auto_remove":
          actualKey = CONFIG_KEYS.GPT_AUTO_REMOVE;
          displayName = "è‡ªåŠ¨åˆ é™¤";
          break;
        case "_set_max_tokens":
          actualKey = CONFIG_KEYS.GPT_MAX_TOKENS;
          displayName = "æœ€å¤§Tokenæ•°";
          break;
        case "_set_collapse":
          actualKey = CONFIG_KEYS.GPT_COLLAPSE;
          displayName = "æŠ˜å å¼•ç”¨";
          break;
        default:
          await msg.edit({ text: "âŒ æœªçŸ¥çš„é…ç½®é¡¹" });
          return;
      }
      
      ConfigManager.set(actualKey, configValue);
      const confirmMsg = await msg.edit({ 
        text: `âœ… å·²è®¾ç½® ${displayName}: \`${actualKey === CONFIG_KEYS.GPT_KEY ? configValue.substring(0, 8) + "..." : configValue}\``,
        parseMode: "markdown"
      });
      
      await sleep(5000);
      await confirmMsg.delete();
      return;
    }

    // è·å–é—®é¢˜æ–‡æœ¬
    let question = args.join(" ");
    const replyMsg = await msg.getReplyMessage();
    let questionType: string | null = null;

    // æ£€æŸ¥æ˜¯å¦æœ‰åª’ä½“ï¼ˆå›¾ç‰‡ï¼‰
    const hasMedia = msg.media || (replyMsg?.media);
    const useVision = hasMedia;

    if (useVision) {
      if (!question) {
        question = "ç”¨ä¸­æ–‡æè¿°æ­¤å›¾ç‰‡";
        questionType = "empty";
      }
      
      // ä¸‹è½½å¹¶å¤„ç†å›¾ç‰‡
      await msg.edit({ text: "ğŸ¤” ä¸‹è½½å›¾ç‰‡ä¸­..." });
      const { imagePath, imageSource } = await downloadAndProcessImage(
        msg.client as Api.TelegramClient,
        msg,
        msg
      );
      tempImagePath = imagePath;

      // å¦‚æœå›å¤æ¶ˆæ¯æœ‰æ–‡æœ¬ï¼Œå°†å…¶åŠ å…¥é—®é¢˜
      if (replyMsg?.text && questionType !== "empty") {
        const replyText = replyMsg.text.trim();
        if (replyText) {
          question = `å›å¤å†…å®¹: ${replyText}\n\né—®é¢˜: ${question}`;
        }
      }

      await msg.edit({ text: "ğŸ¤” æ€è€ƒä¸­..." });
      
      // è°ƒç”¨GPT API
      const answer = await callGptApi(question, imageSource, true);
      
      // æ ¼å¼åŒ–å¹¶å‘é€å›å¤
      const formattedText = formatResponse(question, answer);
      await msg.edit({ 
        text: formattedText,
        linkPreview: false,
        parseMode: "html"
      });

    } else {
      // æ–‡æœ¬é—®ç­”æ¨¡å¼
      if (!question) {
        questionType = "empty";
        if (!replyMsg?.text) {
          await msg.edit({ text: "âŒ è¯·ç›´æ¥æé—®æˆ–å›å¤ä¸€æ¡æœ‰æ–‡å­—å†…å®¹çš„æ¶ˆæ¯" });
          return;
        }
        question = replyMsg.text.trim();
        if (!question) {
          await msg.edit({ text: "âŒ è¯·ç›´æ¥æé—®æˆ–å›å¤ä¸€æ¡æœ‰æ–‡å­—å†…å®¹çš„æ¶ˆæ¯" });
          return;
        }
        question = "å°½å¯èƒ½ç®€çŸ­åœ°å›ç­”: " + question;
      } else if (replyMsg?.text) {
        // å¦‚æœæ—¢æœ‰å‚æ•°åˆæœ‰å›å¤ï¼Œå°†å›å¤å†…å®¹åŠ å…¥é—®é¢˜
        const replyText = replyMsg.text.trim();
        if (replyText) {
          question = `å›å¤å†…å®¹: ${replyText}\n\né—®é¢˜: ${question}`;
        }
      }

      await msg.edit({ text: "ğŸ¤” æ€è€ƒä¸­..." });
      
      // è°ƒç”¨GPT API
      const answer = await callGptApi(question, undefined, false);
      
      // æ ¼å¼åŒ–å¹¶å‘é€å›å¤
      const formattedText = formatResponse(
        questionType === "empty" ? "" : question, 
        answer
      );
      await msg.edit({ 
        text: formattedText,
        linkPreview: false,
        parseMode: "html"
      });
    }

    // è‡ªåŠ¨åˆ é™¤ç©ºæé—®
    const autoRemove = ConfigManager.get(CONFIG_KEYS.GPT_AUTO_REMOVE).toLowerCase() === 'true';
    if (autoRemove && questionType === "empty") {
      await sleep(1000);
      await msg.delete();
    }

  } catch (error: any) {
    console.error("GPTå¤„ç†é”™è¯¯:", error);
    
    const errorMsg = `âŒ é”™è¯¯ï¼š${error.message}`;
    await msg.edit({ text: errorMsg });
    await sleep(10000);
    await msg.delete();

    // è‡ªåŠ¨åˆ é™¤ç©ºæé—®ï¼ˆå³ä½¿å‡ºé”™ï¼‰
    const autoRemove = ConfigManager.get(CONFIG_KEYS.GPT_AUTO_REMOVE).toLowerCase() === 'true';
    if (autoRemove && args.length === 0) {
      await sleep(1000);
      await msg.delete();
    }
  } finally {
    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    await cleanupTempFile(tempImagePath);
  }
}

const gptPlugin: Plugin = {
  command: ["gpt"],
  description: `
GPT åŠ©æ‰‹æ’ä»¶ï¼š
ç›´æ¥æé—®æˆ–å›å¤ä¸€æ¡æ¶ˆæ¯ï¼ˆè‡ªåŠ¨è¯†åˆ«å›¾ç‰‡ï¼‰

é…ç½®å‘½ä»¤ï¼š
â€¢ gpt _set_key <APIå¯†é’¥> - è®¾ç½®APIå¯†é’¥
â€¢ gpt _set_api <APIåœ°å€> - è®¾ç½®APIåœ°å€ï¼ˆé»˜è®¤: https://api.openai.comï¼‰
â€¢ gpt _set_model <æ¨¡å‹å> - è®¾ç½®æ–‡æœ¬æ¨¡å‹ï¼ˆé»˜è®¤: gpt-4oï¼‰
â€¢ gpt _set_vision_model <æ¨¡å‹å> - è®¾ç½®å›¾åƒè¯†åˆ«æ¨¡å‹ï¼ˆé»˜è®¤: gpt-4oï¼‰
â€¢ gpt _set_image_upload <true/false> - å¯ç”¨å›¾ç‰‡ä¸Šä¼ ï¼ˆé»˜è®¤: falseï¼‰
â€¢ gpt _set_web_search <true/false> - å¯ç”¨Webæœç´¢ï¼ˆé»˜è®¤: falseï¼‰
â€¢ gpt _set_auto_remove <true/false> - è‡ªåŠ¨åˆ é™¤ç©ºæé—®ï¼ˆé»˜è®¤: falseï¼‰
â€¢ gpt _set_max_tokens <æ•°é‡> - è®¾ç½®æœ€å¤§Tokenæ•°ï¼ˆ-1è¡¨ç¤ºä¸é™åˆ¶ï¼Œé»˜è®¤: 888ï¼‰
â€¢ gpt _set_collapse <true/false> - å¯ç”¨æŠ˜å å¼•ç”¨ï¼ˆé»˜è®¤: falseï¼‰

ä½¿ç”¨ç¤ºä¾‹ï¼š
1. gpt ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ
2. å›å¤ä¸€æ¡æ¶ˆæ¯åä½¿ç”¨ gpt
3. å‘é€å›¾ç‰‡å¹¶ä½¿ç”¨ gpt æè¿°å›¾ç‰‡å†…å®¹
  `,
  cmdHandler: handleGptRequest,
};

export default gptPlugin;
